-
  id: 100
  title: "Registration"
  place: "Hall"
  service: true
  description: "Come early and enjoy breakfast with us."
-
  id: 101
  title: "Coffee Break"
  place: "Hall"
  service: true
  description: "Everyone deserves a little break to relax and engage with the speakers and other attendees."
-
  id: 102
  title: "Lunch Break"
  place: "Dining room"
  service: true
  description: "A stand-up lunch will be served and we will provide vegetarian and gluten-free options."
-
  id: 103
  title: "BEERS"
  place: "Hall"
  service: true
  description: "After a long day of talks what better than enjoying a beer and meet everyone!"
-
  id: 001
  title: "Welcome"
  description: "Eiso Kant, CEO & Co-Founder at source{d}, will introduce the event briefly before we get started."
  subtype: presentation
  speakers: [Eiso Kant]
  language: en
  complexity: "Intermediate"
-
  id: 002
  title: "Statistical Analysis of Computer Program Text"
  description: "Billions of lines of source code have been written, many of which are freely available on the Internet. This code contains a wealth of implicit knowledge about how to write software that is easy to read, avoids common bugs, and uses popular libraries effectively. 

We want to extract this implicit knowledge by analyzing source code text. To do this, we employ the same tools from machine learning and natural language processing that have been applied successfully to natural language text. After all, source code is also a means of human communication.

We present three new software engineering tools inspired by this insight:

Naturalize, a system that learns local coding conventions. It proposes revisions to names and to formatting so as to make code more consistent. A version that uses word embeddings has shown promise toward naming methods and classes.

Data mining methods have been widely applied to summarize the patterns about how programmers invoke libraries and APIs. We present a new method for mining market basket data, based on a simple generative probabilistic model, that resolves fundamental statistical pathologies that lurk in popular current data mining techniques.

HAGGIS, a system that learns local recurring syntactic patterns, which we call idioms. HAGGIS accomplishes this using a nonparametric Bayesian tree substitution grammar, and is delicious with whisky sauce."
  subtype: presentation
  speakers: [4]
  language: en
  complexity: "Intermediate"
-
  id: 003
  title: "Similarity of GitHub repositories by source code identifiers"
  description: ""
  subtype: presentation
  speakers: [6]
  language: en
  complexity: "Intermediate"
-
  id: 004
  title: "Sequence Learning and modern RNNs"
  description: ""
  subtype: presentation
  speakers: [8]
  language: en
  complexity: "Intermediate"
-
  id: 005
  title: "Probabilistic Programming for Mere Mortals"
  description: "It is an introductory talk about the subject which became popular in recent years. The talk will cover few crucial aspects of the subject such as what is probabilistic programming and what kind of problems probabilistic programming can solve? Its relationship with machine learning techniques also will be covered. Tools and programming languages will be mentioned in the context of practical applications of probabilistic programing. Moreover we will discuss some ideas about how to implement probabilistic programming language and how to embed probabilistic programming capabilities into a general purpose programming language. No preliminary knowledge about the subject is required."
  subtype: presentation
  speakers: [9]
  language: en
  complexity: "Intermediate"
-
  id: 006
  title: "Sequence Learning and modern RNNs"
  description: ""
  subtype: presentation
  speakers: [10]
  language: en
  complexity: "Intermediate"
-
  id: 007
  title: "Neural Complete - A Neural Network to help humans write neural networks"
  description: "In this talk, it will be shown how to generate auto completion suggestions for code by using a neural network. Such a neural network is not only capable of utilising personal code, but also benefits from massive datasets containing previously written code. The architecture of the neural network will be explained; we will zoom in on the current limitations, and possible improvements will be discussed.

The 'Neural Complete' framework is available (https://github.com/kootenpv/neural_complete) for quickly testing new
neural network models on all sorts of code related data."
  subtype: presentation
  speakers: [7]
  language: en
  complexity: "Intermediate"
-
  id: 302
  title: "Embedding the GitHub contribution graph"
  description: ""
  subtype: lighting
  speakers: [5]
  language: en
  complexity: "Intermediate"
-
  id: 303
  title: "Predicting memory allocations using a recurrent neural network"
  description: ""
  subtype: lighting
  speakers: [6]
  language: en
  complexity: "Intermediate"
